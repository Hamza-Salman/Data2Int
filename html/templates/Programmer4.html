{% extends "base.html" %}
{% block title %}Programmer4 Archives{% endblock %}

{% block content %}
    <h1> Code Changes</h1>

    <h1>Progress Update</h1>

    <ul class="nav nav-pills mb-3" id="pills-tab" role="tablist">
        <li class="nav-item">
            <a class="nav-link active" id="pills-research-tab" data-toggle="pill" href="#pills-research" role="tab"
               aria-controls="pills-research" aria-selected="true">Research</a></li>
        <li class="nav-item">
            <a class="nav-link" id="pills-upload-research-tab" data-toggle="pill" href="#pills-upload-research"
               role="tab" aria-controls="pills-upload-research" aria-selected="false">File Upload Research</a></li>
        <li class="nav-item">
            <a class="nav-link" id="pills-virus-scanning-files-tab" data-toggle="pill" href="#pills-virus-scan"
               role="tab" aria-controls="pills-virus-scan" aria-selected="false">Virus Scanning Files</a></li>
        <li class="nav-item">
            <a class="nav-link" id="pills-mongo-tab" data-toggle="pill" href="#pills-mongo"
               role="tab" aria-controls="pills-mongo" aria-selected="false">Setting Data Expiry in MongoDB</a></li>
        <li class="nav-item">
            <a class="nav-link" id="pills-personal-project-tab" data-toggle="pill" href="#pills-personal-project"
               role="tab" aria-controls="pills-personal-project" aria-selected="false">Personal Project: Covid-19</a></li>
    </ul>

    <div class="tab-content" id="pills-tabContent">
        <div class="tab-pane fade show active" id="pills-research" role="tabpanel" aria-labelledby="pills-research-tab">
            <hr/>
            <strong><a data-toggle="collapse" href="#data-analysis-techniques">Data Analysis Techniques</a></strong>
            <div id="data-analysis-techniques" class="collapse">
                <a target="_blank" href="https://careerfoundry.com/en/blog/data-analytics/data-analysis-techniques/">Link</a>
                <p>Quantative data – anything measurable usually numerical figures and quantities. Ex. Sales figures,
                    website visitors, and percents of revenue increase.<br>
                    Quantative data analysis techniques – focuses on statistical, mathematical, or numerical analysis.
                    Uses algorithms and computational techniques to explain patterns and make predictions<br>
                    Qualitative data – cannot be measured objectively and more open to interpretation. Qualitative data
                    can include comments on a survey, product reviews, and social media posts<br>
                    Qualitative data analysis techniques – makes sense of the unstructured data and is organized into
                    themes.<br>
                    Covers 7 most useful methods of data analysis:</p>
                <ul>
                    <li>Regression analysis – estimate how one or more variables might impact the dependent variable, in
                        order to identify trends and patterns. This is especially useful for making predictions and
                        forecasting future trends.
                    </li>
                    <li>Monte Carlo simulation - a computerized technique used to generate models of possible outcomes
                        and their probability distributions. It considers a range of possible outcomes and then
                        calculates how likely it is that each particular outcome will be realized. Used by data analysts
                        to conduct advanced risk analysis.
                    </li>
                    <li>Factor analysis - a technique used to reduce a large number of variables to a smaller number of
                        factors. It works on the basis that multiple separate, observable variables correlate with each
                        other because they are all associated with an underlying construct; this is called covariance.
                        This allows datasets to be compressed into smaller samples and uncover hidden patterns, like
                        concepts that aren’t easily measured.
                    </li>
                    <li>Cohort analysis – a technique that divides data that has common characteristics into related
                        groups for analysis. Often used to target more specific customer segments and personalized
                        experience.
                    </li>
                    <li>Cluster analysis – sorts different data points into groups that are similar to each other and
                        not similar to data points in another cluster. Seeks to find structures within the dataset
                    </li>
                    <li>Time series analysis – a sequence of data points which measure the same variable at different
                        points in time. Used to identify trends and cycles over time and allows analysts to forecast how
                        they may fluctuate in the future.
                    </li>
                    <li>Sentiment analysis – the process of sorting and understanding textual data to interpret and
                        classify the emotions conveyed within the textual data. This allows to gain a feeling of how
                        your customers satisfaction about the brand or service.
                    </li>
                </ul>
            </div>
            <br>

            <strong><a data-toggle="collapse" href="#hashing-python">Hashing Algorithms in Python</a></strong>
            <div id="hashing-python" class="collapse">
                <a target="_blank" href="https://docs.python.org/3/library/hashlib.html">Link</a>
                <p>Covers the following hashing library in Python called hashlib</p>
                <p>Types of hash algorithms included:</p>
                <ul>
                    <li>SHA1</li>
                    <li>SHA224</li>
                    <li>SHA256</li>
                    <li>SHA384</li>
                    <li>SHA512</li>
                    <li>MD5</li>
                </ul>

                <strong>Hashlib Properties</strong>
                <ul>
                    <li>algorithms_guaranteed - a set containing the list of algorithms that are supported by the module
                        on all platforms
                    </li>
                    <li>algorithms_available - a set of algorithms that are available in the running Python
                        interpreter.
                    </li>
                </ul>

                <strong>Hash Properties - Constants</strong>
                <ul>
                    <li>digest_size - the byte size of the hash result</li>
                    <li>block_size - the internal block size of the hash algorithm in bytes</li>
                </ul>

                <strong>Hash Properties - instance variables</strong>
                <ul>
                    <li>name - the canonical name of the hash in lowercase. Can be used with <i>new()</i> as a parameter
                        to make an instance of a hash of the corresponding type
                    </li>
                </ul>

                <strong>Hash Functions</strong>
                <ul>
                    <li>update(data) - updates the object with bytes-like object (ex: bytes, byte array, etc)</li>
                    <li>digest() - returns a digest of data passed to update() method. Acceptable range is 0 to 255</li>
                    <li>hexdigest() - similar to digest() except it returns a string only containing hexadecimal
                        digits
                    </li>
                    <li>copy() - makes a copy of the object</li>
                </ul>
            </div>
            <br>

            <strong><a data-toggle="collapse" href="#geomaps-with-python">PyCon - Finding a Home in Singapore Using a
                Data Driven Approach</a></strong>
            <div id="geomaps-with-python" class="collapse">
                <a target="_blank" href="https://www.youtube.com/watch?v=PInO2Cluu2E">Link</a>
                <p>A woman used open data to find an ideal home in Singapore<br><br>
                    99.co – property search portal, used to look up rental/Airbnb<br><br>
                    Even after entering search parameters, still faced with thousands of listings<br><br>
                    Problem: how do you choose best possible listing?<br><br>
                    First, looked at MRT station is cheapest to live around. Made a map visualization<br><br>
                    Used geolocation file of MRT map around Singapore. Data comes in both .shp and .dbf file types,
                    which are read by shapefile. Reader in Python to read the records<br><br>
                    Next, she checked how many shape objects are in the shape file, corresponds to the number of MRT
                    stations in Singapore. Then check the type of shapes in the shape file.<br><br>
                    Next, she prints the fields of the object. Prints out [variable name, the type of field as an
                    abbreviation, the max size of the field, number of decimal places (if applicable. If not, default
                    value is 0)]<br><br>
                    Next she iterates through the first 3 records, which prints out coordinates for the object, which is
                    a train station in Singapore, in latitude/longitude. Singapore has it’s own coordinate system which
                    she then converts the coordinates to, to get a more accurate location, within the city, using an SVY
                    package library in Python.<br><br>
                    Now that the coordinates are converted, she uses Basemap (another Python library to plot maps) to
                    plot the maps coordinates and draw the outline of the country, and add markers to the map. Then she
                    uses Folium, a Python package, to make the map. Next iterate through the list of coordinates and add
                    a marker for each record, and adds the name attribute as a pop-up for each coordinate.<br><br>
                    Next she computes the price per square foot around each station. To do this, she retrieves open
                    source data about housing and development prices. Problem is the data doesn’t contain coordinate
                    information; to compensate for this, she uses an API to submit an address, which returns the
                    coordinates. Now she uses GeoPy to compute the distances between addresses. She also filters out
                    coordinates that are more than 1km from the stations.<br>
                    She then iterates through the stations and uses pre-computed transactions over the past 3 months, 1
                    km from the stations, and normalizes them. If zero, the markers are color coded as white; otherwise,
                    she uses the 0-1 scale value to determine a hue based on the price. Blue for lowest cost and red for
                    highest. Finally, she adds a price to the marker.<br><br>
                    The result is that the prices in the central business districts are more expensive than elsewhere,
                    which is not surprising. But the rate at which the prices decline at a further rate closer to the
                    border at about x2 vs closer to the central business district x4. As a result, she was able to make
                    a data driven decision about where to live. <br><br>
                    The rest of the video is just her going over source code on both Github and jupyter. Also live
                    editing code to display visual changes to the map to the audience, like changing the marker shapes
                    and colors
                </p>
            </div>
            <br>

            <strong><a data-toggle="collapse" href="#download-csv-url">Downloading CSV from a URL in Python</a></strong>
            <div id="download-csv-url" class="collapse">
                <a target="_blank"
                   href="https://www.kite.com/python/answers/how-to-download-a-csv-file-from-a-url-in-python">Link</a>
                <br>Basic steps of downloading a csv file from URL:
                <ol>
                    <li>Use a GET request with the CSV url</li>
                    <li>Generate the content from the response</li>
                    <li>Open the the file using <i>wb</i> mode</li>
                    <li>Write the contents of the file to he desired location</li>
                    <li>Close the file</li>
                </ol>
            </div>
            <br>

            <strong><a data-toggle="collapse" href="#multiple-linear-regression">Multiple Linear Regression using
                Python</a></strong>
            <div id="multiple-linear-regression" class="collapse">
                <a target="_blank" href="https://www.youtube.com/watch?v=BETGdxOA1ss">Link</a>
                <br>Basic steps:
                <ol>
                    <li>Import the data</li>
                    <li>Check for data that has null values (NaN). If any records appear with null values, replace it
                        with constant(numerical value)
                    </li>
                    <li>Split data into coordinates; input values as <i>x</i> and output as <i>y</i>, as a numpy array
                    </li>
                    <li>Split the coordinates into random train and test subsets, using a percentage floating point
                        value that defines the subset to use
                    </li>
                    <li>Use model.score() using xTest and yTest values to calculate your accuracy percentage</li>
                    <li>Perform a linear regression on the object and perform a fit using the X and Y train values</li>
                    <li>Use model.predict() using the xTest to return an array of prediction values</li>
                    <li>Iterate through the array of test values and use the yTest values (at the current index) minus
                        the test value to get the margin of error
                    </li>
                </ol>
            </div>

        </div>
        <div class="tab-pane fade" id="pills-upload-research" role="tabpanel"
             aria-labelledby="pills-upload-research-tab">
            <h2>Uploading JSON Files</h2>
            <a target="_blank"
               href="https://www.freecodecamp.org/news/python-read-json-file-how-to-load-json-from-a-file-and-parse-dumps/">Link</a>
            <p>To read the contents of a JSON file, use the statement <i>import json</i> to use a Python library
                dedicated to JSON files. Use a <i>with</i> statement
                and the function <i>open(filename)</i> to open the JSON as a file. Then use <i>json.loads(myString)</i>
                to parse the data into a dictionary. From there,
                you can manipulate the data to create your own Python objects.</p>
        </div>
        <div class="tab-pane fade" id="pills-virus-scan" role="tabpanel" aria-labelledby="pills-virus-scan-tab">
            <h2>Virus Scanning Files</h2>
            <hr>


            <p>If your website allows users to upload files to a server, your server needs to be protected from any
                malicious hackers out there.
                There's no easy solution to implementing virus scanning protection on your website outside of purchasing
                your own virus scanning software. Fortunately, SharpAPIs provides a more cost effective solution.</p>

            <p>Free to use, <a target="_blank" href="https://app.sharpapis.com/#/login">sharpapis</a> allows you to send
                the file for a virus scan via a POST request and the response contains the result. However, the free
                plan only
                contains 100 free scans, which refresh every 21 days, but it can be upgraded to 1000, or more as needed
                for an added cost.</p>

            <p>

            <ol>
                <li>Sign up for an account and confirm your account using the email they send. Be sure to check your
                    Junk mail folder!
                </li>
                <li>Grab your X-ApplicationID and your X-Secret Key from your account and record them for later.</li>
                <br>
            </ol>

            <h3>Python version</h3>

            <ol start="3">
                <li>Install the request and json libraries</li>

                <pre class="command-line language-bash" data-user="root" data-host="localhost" tabindex="0">
            <code class="language-bash">
                <span class="command-line-prompt">
                    <span data-user="root" data-host="localhost"></span>
                    <span class="token builtin class-name">pip3</span> install request
                    <span class="token builtin class-name">pip3</span> install json
                </span>
            </code>
        </pre>
                <br>

                <li>Next I created a new script called <b>virusScanFile.py</b></li>

                <li>Create the url and the directory to fetch the file. Then, in the header of the request,
                    use the X-ApplicationID and X-SecretKey you wrote down earlier as strings in the header.
                </li>
                <pre>
            <code class="language-javascript">
                <script type="prism-python">
                import requests
                import json


                        # End point we're sending the request to
                        endpoint = "https://api.virusscannerapi.com/virusscan"

                        # Give the directory files will be sent to
                        filepath = "C:/Users/<YourName>/<directory>"

                        # create the request header with the ID and secret key from your account
                        headers = {
                        'X-ApplicationID': 'myFakeID',
                        'X-SecretKey': 'myFakeSecretKey'
                       }

                </script>
            </code>
        </pre>
                <br/>

                <li>Open the file using "rb" mode, define data and files using the filename and reading the file in.
                </li>
                <pre>
            <code class="language-javascript">
                <script type="prism-python">

                # open the file
                file = open(filepath + filename, "rb")

                # define as a synchronous process
                data = {
                'async': 'false',
                }

                # add the file to the array of files to send
                files = {
                'inputFile': ('\'' + filename + '\'', file.read())
                }

</script>
            </code>
        </pre>
                <br/>

                <li>Send as a POST request using the 4 parameters, and check the response for the result</li>
                <pre>
            <code class="language-javascript">
                <script type="prism-python">
                       # await the response using a POST request
                       r = requests.post(url=endpoint, data=data, headers=headers, files=files)

                       # convert the JSON response text into a dictionary
                       response = json.loads(r.text)

                       # Check the string for the status. Files without any issues will return "File is clean"
                       if response["status"] != "File is clean":
                       #do something
</script>
            </code>
        </pre>
                <br/>
            </ol>
            </p>
            <p>
            <h3>C# version</h3>
            <ol start="3">
                <li>Install the Newtonsoft.Json library from the NuGet Package Manager.</li>
                <li>Setup the function in your controller</li>
                <li>Create the url and the directory to fetch the file. Then, in the header of the request,
                    use the X-ApplicationID and X-SecretKey you wrote down earlier as strings in the header.
                </li>
                <pre>
            <code class="language-javascript">
                <script type="prism-python">
                    namespace MyProgram {
                        public class VirusScanResponse {
                            public int id { get; set; }
                            public string userId { get; set; }
                            public string fileName { get; set; }
                            public DateTime startedAt { get; set; }
                            public DateTime finishedAt { get; set; }
                            public string status { get; set; }
                            public string userIpAddress { get; set; }
                        }

                        public class MyController : BaseController {

                            public async Task<bool> VirusScanFile() {
                            await using (HttpClient client = new HttpClient())
                            {

                            // Adding authentication headers
                            client.DefaultRequestHeaders.Add("X-ApplicationID", "myFakeID");
                            client.DefaultRequestHeaders.Add("X-SecretKey", "myFakeSecretKey");
                </script>
            </code>
        </pre>
                <br/>
                <li>Open the file using "rb" mode, define data and files using the filename and reading the file in.
                </li>
                <pre>
            <code class="language-javascript">
                <script type="prism-python">
                            var filepath = @"C:/Users/<YourName>/<directory>";

                            using (var requestContent = new MultipartFormDataContent("Upload----" + DateTime.Now.ToString(CultureInfo.InvariantCulture)))
                            {
                            // Setting body parameters
                            requestContent.Add(new StringContent(filepath), "inputFile");
                            requestContent.Add(new StringContent("false"), "async");
                </script>
            </code>
        </pre>
                <br/>

                <li>Send as a POST request using the 4 parameters, and check the response for the result</li>
                <pre>
            <code class="language-javascript">
                <script type="prism-python">
                // Sending a POST request to DCA API
                using (var requestResultTask = await client.PostAsync("https://api.virusscannerapi.com/virusscan", requestContent))
                {
                    var result = await requestResultTask.content.ReadAsStringAsync();
                    var response = Newtonsoft.Json.JsonConvert.DeserializeObject<VirusScanResponse>(result);

                    if (response.status != "File is clean")
                    {
                        //do something
                    }
                </script>
            </code>
        </pre>
                <br/>
            </ol>

            <h4>Implementation notes: </h4>
            <ul>
                <li>Files need to be uploaded to the server first before they can be read and scanned, unless you are
                    sending a file from a URL.
                </li>
                <li>If the file size is over 50000KB, your request may return a response with a 400 series error because
                    there is too much content in the request.
                    You may want to consider scanning portions of the file instead of the whole thing at a time
                </li>
                <li>If you are reading directly from the file, the file content needs to be read as binary format before
                    being inserted into the request content.
                </li>
                <li>SharpApis also provides ways to get statuses from previous virus scans if you send the id of the
                    scan as a GET request. This is particularly useful for auditing
                    if you are storing all scans in a database and want to search on the status of a particular scan in
                    the future.
                </li>
            </ul>

            <a href="https://www.docconversionapi.com/blog/scan-file-virus-using-python/">Source</a>
            </p>
        </div>
        <div class="tab-pane fade" id="pills-mongo" role="tabpanel" aria-labelledby="pills-mongo-tab">

            <h2>Setting Data Expiry in MongoDB</h2>
            <hr>

            <p>Usually when data is inserted into a database, the data is generally considered persistent cause most cases
            the data is stored permanently in records. However, the drawback of this is storage and memory concerns, as memory isn't
            an infinite resource. For the Data2Int website, data that is uploaded by users doesn't persist for longer than 24hrs.</p>

            <p>I tried a couple different approaches to this as a developer. I first tried writing a scheduling task within the application,
            that would call a function at a scheduled time. </p>

            <pre>
            <code class="language-javascript">
                <script type="prism-python">
                    import schedule
                    import time

                    from pymongo import MongoClient, errors


                    # function to purge the Mongo DB of user uploaded data
                    def purge_data(db_host=27017, db_port='localhost'):

                    try:
                        # Establish database connection with MongoDB
                        connection = MongoClient(db_host, db_port)

                        # Store a list of database names at the current connection
                        dbs = connection.list_database_names()

                        # Loop through list of database names
                        for db_count, db in enumerate(dbs):

                        # Grab a list of collection names in the database
                        collections = connection[db].list_collection_names()

                        for col_count, col in enumerate(collections):
                        # Grab the collection's name at that index
                        collection_name = connection[db][col].name

                        # Skip over any collection named 'donorschoose'
                        if collection_name == 'donorschoose':
                            continue

                        # TODO: add checks for collections being used by website as static content

                        # drop the database at the index using each string in the list
                        connection[db].drop_collection(collection_name)

                        print("Purging data.")

                        connection.close()

                    except errors.ConnectionFailure as err:
                        client = None

                        print("Daily database purge cannot be completed:", err)

                        # schedule a task that will execute this function at midnight everyday
                        schedule.every().day.at("00:00").do(purge_data)

                        while True:
                        # Checks for a pending task to run
                        schedule.run_pending()
                        time.sleep(1)
                </script>
            </code>
        </pre>

            <p>However, the problem with this approach comes with trying to call this task within the application, as it needs
            to run on its own, rather than be triggered by a web page event. That was one of the main reasons this approach didn't work.</p>

            <p>After further research and reaching out online for help from others, I learned of TTL Indexes in MongoDB. "TTL indexes are special
            single-field indexes that MongoDB can use to automatically remove documents after a certain amount of time or specific clock time..." [1].
            A background thread in mongod runs every 60 seconds; it should be noted that data may persist beyond the 60 second mark depending on the speed
            of the background process.</p>

            <p>To specify the amount of time you want the data to last, use the <i>create_index</i> function and overload the <i>expiryAfterSeconds</i> property.
            You can manually specify the time by feeding this value as seconds.</p>

            <pre>
            <code class="language-javascript">
                <script type="prism-python">
                    from pymongo import MongoClient
                    import csv

                    connection = MongoClient(DB_HOST, DB_PORT)

                    collection = connection[DB_Name][COLLECTION_NAME]
                    csvFile = open(path_to_file + "/" + uploaded_file, 'r')
                    reader = csv.DictReader(csvFile)

                    collection.create_index("expire_date_time", expireAfterSeconds=seconds_until_end_of_day())
                    collection.insert_many(reader)

                    connection.close()
                </script>
            </code>
        </pre>

            <p>You can either pass a hardcoded value, like 86400 (the number of seconds in a day). If you need this to happen around a specified time,
            this is possible, but you would need to calculate the difference in time yourself. You can do this by using a function to return a timedelta,
            which is exactly the change in the time and using the datetime module in Python. The following example shows
            you how to calculate the difference in time with midnight in mind.</p>

            <pre>
            <code class="language-javascript">
                <script type="prism-python">
                from datetime import datetime, timedelta


                def seconds_until_end_of_day():
                    dt = datetime.utcnow()
                    tomorrow = dt + timedelta(days=1)
                    midnight = datetime(year=tomorrow.year, month=tomorrow.month,
                                        day=tomorrow.day, hour=0, minute=0, second=0)

                    return (midnight - datetime.utcnow()).seconds
                </script>
            </code>
        </pre>

            <p>This is just one of a few ways to calculate the time remaining, but it should be noted that using the
            UTC timezone value is considered best practice rather, than using the local datetime.</p>

            <p>Source:<a href="https://docs.mongodb.com/manual/core/index-ttl">[1] TTL Indexes</a></p>
        </div>
    <div class="tab-pane fade" id="pills-personal-project" role="tabpanel" aria-labelledby="pills-personal-project-tab">
        <h2>Personal Project: Covid-19</h2>
        <hr>

        <h3>Preface</h3>

        <p>The purpose of this project will be to analyze Covid-19 trends within the past year and a half, with a focus on trends in Ontario,
        and possibly a comparison between other Canadian provinces. Topics of interest that I am hoping to cover are case counts per PHU in Ontario over time,
        vaccination rates compared between Ontario cities/PHUs, case count comparisons between Ontario and other provinces, etc. These visualizations will be used to uncover
        persisting trends and give an overall analysis of how Ontario has fared the pandemic up to this point. We'll also use this compare between cities/PHUs how they each have
        fared the pandemic in comparison to each other.</p>

        <style> /* set the CSS */
        path {
            stroke: steelblue;
            stroke-width: 2;
            fill: none;
        }
        .axis path,
        .axis line {
            fill: none;
            stroke: grey;
            stroke-width: 1;
            shape-rendering: crispEdges;
        }

        .legend {
            font-size: 16px;
            font-weight: bold;
            text-anchor: middle;
        }
        </style>

        -<div id="charts">
            <!-- load the d3.js library -->
            <script src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.17/d3.min.js"></script>
            <script src="/static/js/markCovidGraphs.js"></script>
        </div>

    </div>

    </div>



{% endblock %}
